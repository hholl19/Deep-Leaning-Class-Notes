{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Applied Deep Learning 2nd Notebook.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM2SW7RNhfYNFOYIazljYDV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hholl19/Deep-Leaning-Class-Notes/blob/hholl19_added_things/Applied_Deep_Learning_2nd_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDWJK55hHSeI"
      },
      "source": [
        "**Snake Classifier Model Attempt 3**\n",
        "\n",
        "**Hadassah Holl**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54s1r5k4HfKo"
      },
      "source": [
        "**Load Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wx49vhXevrcO"
      },
      "source": [
        "import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import pathlib \n",
        "from pathlib import Path\n",
        "#import cv2\n",
        "#from tqdm import tqdm\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Dense, Flatten, Conv2D, MaxPooling2D \n",
        "from keras.layers.normalization import BatchNormalization \n",
        "from keras.optimizers import SGD\n",
        "#from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "\n",
        "from numpy import expand_dims\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "#from matplotlib import pyplot"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDrjAvpyHyuV"
      },
      "source": [
        "**Mounted Google Drive and wrote in Path directly to my Google Drive to Gain Access to full Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4EJpjIYxTsj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "719a8077-7193-4cb6-c5d9-89a949b3491f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EI3pK48OK9b4",
        "outputId": "0b98f1b3-73c4-4e3b-bde4-ef13a1c33fbb"
      },
      "source": [
        "file_path= '/content/drive/MyDrive/Kaggle-Applied Deep Learning Project/Inputs'\n",
        "folders = os.listdir(file_path)\n",
        "print(folders)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['test.csv', 'train.csv', 'train', 'test']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "MB-J5N4Y1nnC",
        "outputId": "55a7e57f-a5f5-4be7-da86-c68a485ec64c"
      },
      "source": [
        "df_train= pd.read_csv('/content/drive/MyDrive/Kaggle-Applied Deep Learning Project/Inputs/train.csv')\n",
        "df_train.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>breed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a8b3ad1dde</td>\n",
              "      <td>nerodia-erythrogaster</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8b492b973d</td>\n",
              "      <td>pantherophis-vulpinus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>929b99ea92</td>\n",
              "      <td>thamnophis-sirtalis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bbac7385e2</td>\n",
              "      <td>pantherophis-obsoletus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ef776b1488</td>\n",
              "      <td>agkistrodon-contortrix</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     image_id                   breed\n",
              "0  a8b3ad1dde   nerodia-erythrogaster\n",
              "1  8b492b973d   pantherophis-vulpinus\n",
              "2  929b99ea92     thamnophis-sirtalis\n",
              "3  bbac7385e2  pantherophis-obsoletus\n",
              "4  ef776b1488  agkistrodon-contortrix"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45BFbQbMIcHE"
      },
      "source": [
        "**Added in image file paths to pull images into CSV for easier processing.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "PJd-FQqh1yBp",
        "outputId": "f2122910-25e5-45b4-f28f-ab35909d221b"
      },
      "source": [
        "df_train[\"image_id\"]=\"/content/drive/MyDrive/Kaggle-Applied Deep Learning Project/Inputs/train/\" + df_train[\"image_id\"] + \".jpg\"\n",
        "df_train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>breed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/Kaggle-Applied Deep Lea...</td>\n",
              "      <td>nerodia-erythrogaster</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/Kaggle-Applied Deep Lea...</td>\n",
              "      <td>pantherophis-vulpinus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/Kaggle-Applied Deep Lea...</td>\n",
              "      <td>thamnophis-sirtalis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/Kaggle-Applied Deep Lea...</td>\n",
              "      <td>pantherophis-obsoletus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/Kaggle-Applied Deep Lea...</td>\n",
              "      <td>agkistrodon-contortrix</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            image_id                   breed\n",
              "0  /content/drive/MyDrive/Kaggle-Applied Deep Lea...   nerodia-erythrogaster\n",
              "1  /content/drive/MyDrive/Kaggle-Applied Deep Lea...   pantherophis-vulpinus\n",
              "2  /content/drive/MyDrive/Kaggle-Applied Deep Lea...     thamnophis-sirtalis\n",
              "3  /content/drive/MyDrive/Kaggle-Applied Deep Lea...  pantherophis-obsoletus\n",
              "4  /content/drive/MyDrive/Kaggle-Applied Deep Lea...  agkistrodon-contortrix"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1D52vqZNVyf"
      },
      "source": [
        "**Load Pre-trained VGG19 Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgyZB9ONzcjL"
      },
      "source": [
        "vgg19 = VGG19(include_top=False,\n",
        "              weights='imagenet',\n",
        "              input_shape=(224,224,3),\n",
        "              pooling=None)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9ixaV-9PFDO"
      },
      "source": [
        "**Freeze the main model layers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmC5lWXa2G0L"
      },
      "source": [
        "for layer in vgg19.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo-VGnFzPcII"
      },
      "source": [
        "*Started the training model, loaded in the pre-trained vgg19, and added some additional layers per class example.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rcKHjIU2Lfo"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(vgg19)\n",
        " \n",
        "model.add(Flatten(name='flattened'))\n",
        "#model.add(Dropout(0.3, name='dropout'))\n",
        "model.add(Dense(35, activation='softmax', name='predictions'))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMKXqrQL2RvQ"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHzDFjJNQJUG"
      },
      "source": [
        "**Adding Data Augmentation and Pre-processing together for Transfer Learning.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDU3SMbJ2bjx"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1/255,\n",
        "        validation_split=0.2,\n",
        "        data_format='channels_last',\n",
        "        rotation_range=30,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='reflect') \n",
        "test_datagen = ImageDataGenerator(\n",
        "        rescale=1.0/255,\n",
        "        data_format='channels_last')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hyRbuke3JFj",
        "outputId": "cf612a7d-d409-426f-fef0-44b6e68dd4ae"
      },
      "source": [
        "train_gen = train_datagen.flow_from_dataframe(\n",
        "        dataframe=df_train,\n",
        "        directory=\"/content/drive/MyDrive/Kaggle-Applied Deep Learning Project/Inputs/train/\",\n",
        "        x_col=\"image_id\",\n",
        "        y_col=\"breed\",\n",
        "        subset=\"training\",\n",
        "        batch_size=32,\n",
        "        seed=123,\n",
        "        shuffle=True,\n",
        "        color_mode=\"rgb\",\n",
        "        class_mode=\"categorical\", \n",
        "        target_size=(224,224)) "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4407 validated image filenames belonging to 35 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-yDwdhc3NfC",
        "outputId": "cbfee3c4-fafc-4ff0-cc84-bd12c0519ff8"
      },
      "source": [
        "test_gen = train_datagen.flow_from_dataframe(\n",
        "        dataframe=df_train,\n",
        "        directory=\"/content/drive/MyDrive/Kaggle-Applied Deep Learning Project/Inputs/train/\",\n",
        "        x_col=\"image_id\",\n",
        "        y_col=\"breed\",\n",
        "        subset=\"validation\",\n",
        "        batch_size=32,\n",
        "        seed=123,\n",
        "        shuffle=True,\n",
        "        color_mode=\"rgb\",\n",
        "        class_mode=\"categorical\", \n",
        "        target_size=(224,224))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1101 validated image filenames belonging to 35 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kK4v218kQXjR"
      },
      "source": [
        "**Training the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApHrAXo_Gjix",
        "outputId": "03e765e7-3035-48b1-9431-4f5effbf6a35"
      },
      "source": [
        "model.fit(train_gen, steps_per_epoch=20, \n",
        "                    epochs=75, validation_data=test_gen, \n",
        "                    validation_steps=20)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "20/20 [==============================] - 40s 936ms/step - loss: 5.2755 - accuracy: 0.0596 - val_loss: 4.3143 - val_accuracy: 0.0812\n",
            "Epoch 2/75\n",
            "20/20 [==============================] - 17s 849ms/step - loss: 3.9920 - accuracy: 0.1035 - val_loss: 4.0277 - val_accuracy: 0.1203\n",
            "Epoch 3/75\n",
            "20/20 [==============================] - 17s 859ms/step - loss: 3.8505 - accuracy: 0.1296 - val_loss: 3.7899 - val_accuracy: 0.1234\n",
            "Epoch 4/75\n",
            "20/20 [==============================] - 22s 1s/step - loss: 3.7518 - accuracy: 0.1279 - val_loss: 4.0684 - val_accuracy: 0.1047\n",
            "Epoch 5/75\n",
            "20/20 [==============================] - 17s 842ms/step - loss: 3.7794 - accuracy: 0.1884 - val_loss: 3.7728 - val_accuracy: 0.1203\n",
            "Epoch 6/75\n",
            "20/20 [==============================] - 18s 898ms/step - loss: 3.6638 - accuracy: 0.1519 - val_loss: 4.0546 - val_accuracy: 0.1031\n",
            "Epoch 7/75\n",
            "20/20 [==============================] - 17s 885ms/step - loss: 3.4159 - accuracy: 0.1710 - val_loss: 3.9794 - val_accuracy: 0.1422\n",
            "Epoch 8/75\n",
            "20/20 [==============================] - 18s 898ms/step - loss: 3.2474 - accuracy: 0.2118 - val_loss: 3.8560 - val_accuracy: 0.1328\n",
            "Epoch 9/75\n",
            "20/20 [==============================] - 17s 846ms/step - loss: 3.0893 - accuracy: 0.2875 - val_loss: 3.8497 - val_accuracy: 0.1391\n",
            "Epoch 10/75\n",
            "20/20 [==============================] - 16s 838ms/step - loss: 3.0636 - accuracy: 0.2694 - val_loss: 4.0295 - val_accuracy: 0.1078\n",
            "Epoch 11/75\n",
            "20/20 [==============================] - 17s 872ms/step - loss: 3.3527 - accuracy: 0.2483 - val_loss: 4.2287 - val_accuracy: 0.1063\n",
            "Epoch 12/75\n",
            "20/20 [==============================] - 18s 901ms/step - loss: 3.1050 - accuracy: 0.2631 - val_loss: 4.2161 - val_accuracy: 0.1156\n",
            "Epoch 13/75\n",
            "20/20 [==============================] - 17s 841ms/step - loss: 2.9483 - accuracy: 0.2697 - val_loss: 3.9799 - val_accuracy: 0.1328\n",
            "Epoch 14/75\n",
            "20/20 [==============================] - 17s 842ms/step - loss: 3.0117 - accuracy: 0.2184 - val_loss: 3.8208 - val_accuracy: 0.1312\n",
            "Epoch 15/75\n",
            "20/20 [==============================] - 18s 902ms/step - loss: 2.9394 - accuracy: 0.2752 - val_loss: 4.0183 - val_accuracy: 0.1266\n",
            "Epoch 16/75\n",
            "20/20 [==============================] - 17s 862ms/step - loss: 2.9654 - accuracy: 0.2924 - val_loss: 3.8067 - val_accuracy: 0.1125\n",
            "Epoch 17/75\n",
            "20/20 [==============================] - 17s 857ms/step - loss: 2.9400 - accuracy: 0.2652 - val_loss: 3.9992 - val_accuracy: 0.1312\n",
            "Epoch 18/75\n",
            "20/20 [==============================] - 17s 858ms/step - loss: 2.7624 - accuracy: 0.3121 - val_loss: 3.6660 - val_accuracy: 0.1406\n",
            "Epoch 19/75\n",
            "20/20 [==============================] - 18s 899ms/step - loss: 2.5834 - accuracy: 0.3164 - val_loss: 3.8885 - val_accuracy: 0.1469\n",
            "Epoch 20/75\n",
            "20/20 [==============================] - 17s 845ms/step - loss: 2.7063 - accuracy: 0.3202 - val_loss: 3.8486 - val_accuracy: 0.1484\n",
            "Epoch 21/75\n",
            "20/20 [==============================] - 16s 836ms/step - loss: 2.5031 - accuracy: 0.3596 - val_loss: 3.7380 - val_accuracy: 0.1437\n",
            "Epoch 22/75\n",
            "20/20 [==============================] - 17s 882ms/step - loss: 2.5669 - accuracy: 0.3246 - val_loss: 3.8728 - val_accuracy: 0.1562\n",
            "Epoch 23/75\n",
            "20/20 [==============================] - 17s 880ms/step - loss: 2.4749 - accuracy: 0.3690 - val_loss: 3.7777 - val_accuracy: 0.1578\n",
            "Epoch 24/75\n",
            "20/20 [==============================] - 18s 905ms/step - loss: 2.5705 - accuracy: 0.3697 - val_loss: 4.0663 - val_accuracy: 0.1406\n",
            "Epoch 25/75\n",
            "20/20 [==============================] - 17s 870ms/step - loss: 2.7137 - accuracy: 0.3219 - val_loss: 3.9387 - val_accuracy: 0.1422\n",
            "Epoch 26/75\n",
            "20/20 [==============================] - 17s 845ms/step - loss: 2.5628 - accuracy: 0.4023 - val_loss: 4.2054 - val_accuracy: 0.1469\n",
            "Epoch 27/75\n",
            "20/20 [==============================] - 17s 862ms/step - loss: 2.4152 - accuracy: 0.3923 - val_loss: 3.9582 - val_accuracy: 0.1578\n",
            "Epoch 28/75\n",
            "20/20 [==============================] - 18s 901ms/step - loss: 2.3990 - accuracy: 0.3981 - val_loss: 4.2133 - val_accuracy: 0.1125\n",
            "Epoch 29/75\n",
            "20/20 [==============================] - 17s 852ms/step - loss: 2.2974 - accuracy: 0.4221 - val_loss: 3.9250 - val_accuracy: 0.1688\n",
            "Epoch 30/75\n",
            "20/20 [==============================] - 17s 842ms/step - loss: 2.2406 - accuracy: 0.4215 - val_loss: 4.5427 - val_accuracy: 0.1609\n",
            "Epoch 31/75\n",
            "20/20 [==============================] - 17s 868ms/step - loss: 2.5181 - accuracy: 0.3731 - val_loss: 3.9696 - val_accuracy: 0.1391\n",
            "Epoch 32/75\n",
            "20/20 [==============================] - 17s 878ms/step - loss: 2.2781 - accuracy: 0.4110 - val_loss: 4.3211 - val_accuracy: 0.1359\n",
            "Epoch 33/75\n",
            "20/20 [==============================] - 17s 845ms/step - loss: 2.5214 - accuracy: 0.3816 - val_loss: 4.1613 - val_accuracy: 0.1484\n",
            "Epoch 34/75\n",
            "20/20 [==============================] - 17s 862ms/step - loss: 2.1617 - accuracy: 0.4373 - val_loss: 4.3973 - val_accuracy: 0.1719\n",
            "Epoch 35/75\n",
            "20/20 [==============================] - 18s 899ms/step - loss: 2.5873 - accuracy: 0.3613 - val_loss: 4.2483 - val_accuracy: 0.1156\n",
            "Epoch 36/75\n",
            "20/20 [==============================] - 17s 848ms/step - loss: 2.2611 - accuracy: 0.4388 - val_loss: 4.0371 - val_accuracy: 0.1375\n",
            "Epoch 37/75\n",
            "20/20 [==============================] - 17s 843ms/step - loss: 1.8989 - accuracy: 0.5076 - val_loss: 4.2236 - val_accuracy: 0.1234\n",
            "Epoch 38/75\n",
            "20/20 [==============================] - 17s 886ms/step - loss: 2.2332 - accuracy: 0.4190 - val_loss: 3.9973 - val_accuracy: 0.1500\n",
            "Epoch 39/75\n",
            "20/20 [==============================] - 18s 895ms/step - loss: 2.1859 - accuracy: 0.4639 - val_loss: 4.2914 - val_accuracy: 0.1531\n",
            "Epoch 40/75\n",
            "20/20 [==============================] - 18s 894ms/step - loss: 2.1766 - accuracy: 0.4171 - val_loss: 3.7834 - val_accuracy: 0.1937\n",
            "Epoch 41/75\n",
            "20/20 [==============================] - 17s 860ms/step - loss: 2.1320 - accuracy: 0.4363 - val_loss: 4.0676 - val_accuracy: 0.1641\n",
            "Epoch 42/75\n",
            "20/20 [==============================] - 17s 845ms/step - loss: 1.9122 - accuracy: 0.4644 - val_loss: 4.0255 - val_accuracy: 0.1484\n",
            "Epoch 43/75\n",
            "20/20 [==============================] - 17s 869ms/step - loss: 2.0587 - accuracy: 0.4586 - val_loss: 4.0836 - val_accuracy: 0.1391\n",
            "Epoch 44/75\n",
            "20/20 [==============================] - 18s 895ms/step - loss: 1.9902 - accuracy: 0.4657 - val_loss: 4.4679 - val_accuracy: 0.1562\n",
            "Epoch 45/75\n",
            "20/20 [==============================] - 17s 849ms/step - loss: 2.2552 - accuracy: 0.4040 - val_loss: 4.5621 - val_accuracy: 0.1328\n",
            "Epoch 46/75\n",
            "20/20 [==============================] - 16s 836ms/step - loss: 2.1482 - accuracy: 0.4476 - val_loss: 4.3032 - val_accuracy: 0.1375\n",
            "Epoch 47/75\n",
            "20/20 [==============================] - 18s 895ms/step - loss: 2.1685 - accuracy: 0.4240 - val_loss: 4.2353 - val_accuracy: 0.1531\n",
            "Epoch 48/75\n",
            "20/20 [==============================] - 17s 871ms/step - loss: 2.0763 - accuracy: 0.4859 - val_loss: 4.1440 - val_accuracy: 0.1656\n",
            "Epoch 49/75\n",
            "20/20 [==============================] - 17s 845ms/step - loss: 2.1626 - accuracy: 0.4892 - val_loss: 4.6609 - val_accuracy: 0.1359\n",
            "Epoch 50/75\n",
            "20/20 [==============================] - 16s 839ms/step - loss: 2.2233 - accuracy: 0.4075 - val_loss: 4.3243 - val_accuracy: 0.1437\n",
            "Epoch 51/75\n",
            "20/20 [==============================] - 18s 899ms/step - loss: 2.0085 - accuracy: 0.4499 - val_loss: 3.9549 - val_accuracy: 0.1469\n",
            "Epoch 52/75\n",
            "20/20 [==============================] - 17s 857ms/step - loss: 1.8348 - accuracy: 0.5016 - val_loss: 4.3256 - val_accuracy: 0.1125\n",
            "Epoch 53/75\n",
            "20/20 [==============================] - 16s 837ms/step - loss: 1.9158 - accuracy: 0.4848 - val_loss: 3.9898 - val_accuracy: 0.1734\n",
            "Epoch 54/75\n",
            "20/20 [==============================] - 17s 856ms/step - loss: 1.7942 - accuracy: 0.5226 - val_loss: 4.5798 - val_accuracy: 0.1453\n",
            "Epoch 55/75\n",
            "20/20 [==============================] - 17s 875ms/step - loss: 2.0686 - accuracy: 0.4583 - val_loss: 4.4711 - val_accuracy: 0.1266\n",
            "Epoch 56/75\n",
            "20/20 [==============================] - 17s 841ms/step - loss: 1.9385 - accuracy: 0.4759 - val_loss: 4.2519 - val_accuracy: 0.1688\n",
            "Epoch 57/75\n",
            "20/20 [==============================] - 17s 847ms/step - loss: 1.8346 - accuracy: 0.5025 - val_loss: 4.4329 - val_accuracy: 0.1625\n",
            "Epoch 58/75\n",
            "20/20 [==============================] - 17s 890ms/step - loss: 1.9677 - accuracy: 0.4937 - val_loss: 4.1893 - val_accuracy: 0.1453\n",
            "Epoch 59/75\n",
            "20/20 [==============================] - 17s 873ms/step - loss: 1.8028 - accuracy: 0.5070 - val_loss: 4.3551 - val_accuracy: 0.1828\n",
            "Epoch 60/75\n",
            "20/20 [==============================] - 17s 890ms/step - loss: 2.0072 - accuracy: 0.5006 - val_loss: 4.4967 - val_accuracy: 0.1422\n",
            "Epoch 61/75\n",
            "20/20 [==============================] - 17s 845ms/step - loss: 1.8768 - accuracy: 0.5030 - val_loss: 4.4268 - val_accuracy: 0.1656\n",
            "Epoch 62/75\n",
            "20/20 [==============================] - 17s 861ms/step - loss: 1.7177 - accuracy: 0.5716 - val_loss: 4.2746 - val_accuracy: 0.1750\n",
            "Epoch 63/75\n",
            "20/20 [==============================] - 18s 903ms/step - loss: 1.8573 - accuracy: 0.4942 - val_loss: 4.9782 - val_accuracy: 0.1219\n",
            "Epoch 64/75\n",
            "20/20 [==============================] - 17s 854ms/step - loss: 1.9444 - accuracy: 0.5104 - val_loss: 4.5787 - val_accuracy: 0.1516\n",
            "Epoch 65/75\n",
            "20/20 [==============================] - 17s 849ms/step - loss: 1.8234 - accuracy: 0.4662 - val_loss: 4.5085 - val_accuracy: 0.1484\n",
            "Epoch 66/75\n",
            "20/20 [==============================] - 17s 874ms/step - loss: 1.7277 - accuracy: 0.5219 - val_loss: 4.1508 - val_accuracy: 0.1375\n",
            "Epoch 67/75\n",
            "20/20 [==============================] - 18s 907ms/step - loss: 1.5855 - accuracy: 0.5856 - val_loss: 4.3164 - val_accuracy: 0.1203\n",
            "Epoch 68/75\n",
            "20/20 [==============================] - 17s 845ms/step - loss: 1.7002 - accuracy: 0.5457 - val_loss: 4.3717 - val_accuracy: 0.1703\n",
            "Epoch 69/75\n",
            "20/20 [==============================] - 17s 846ms/step - loss: 1.6216 - accuracy: 0.5474 - val_loss: 4.5413 - val_accuracy: 0.1172\n",
            "Epoch 70/75\n",
            "20/20 [==============================] - 18s 896ms/step - loss: 1.6294 - accuracy: 0.5597 - val_loss: 4.2327 - val_accuracy: 0.1703\n",
            "Epoch 71/75\n",
            "20/20 [==============================] - 17s 858ms/step - loss: 1.4821 - accuracy: 0.5959 - val_loss: 4.8287 - val_accuracy: 0.1297\n",
            "Epoch 72/75\n",
            "20/20 [==============================] - 17s 841ms/step - loss: 1.7796 - accuracy: 0.5072 - val_loss: 4.4937 - val_accuracy: 0.1437\n",
            "Epoch 73/75\n",
            "20/20 [==============================] - 17s 875ms/step - loss: 1.7594 - accuracy: 0.5492 - val_loss: 4.3666 - val_accuracy: 0.1359\n",
            "Epoch 74/75\n",
            "20/20 [==============================] - 17s 875ms/step - loss: 1.5961 - accuracy: 0.5554 - val_loss: 4.2744 - val_accuracy: 0.1656\n",
            "Epoch 75/75\n",
            "20/20 [==============================] - 17s 893ms/step - loss: 1.7062 - accuracy: 0.5380 - val_loss: 4.4419 - val_accuracy: 0.1344\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f29e04d0b10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfA1SAty3UE2"
      },
      "source": [
        "#model.fit(train_gen, steps_per_epoch=15, \n",
        "                    #epochs=16, validation_data=test_gen, \n",
        "                    #validation_steps=15)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}