{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Applied Deep Learning 2nd Notebook.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOccs+4YUYutAR142qDlvvA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hholl19/Deep-Leaning-Class-Notes/blob/hholl19_added_things/Applied_Deep_Learning_2nd_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wx49vhXevrcO"
      },
      "source": [
        "import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import pathlib \n",
        "from pathlib import Path\n",
        "#import cv2\n",
        "#from tqdm import tqdm\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Dense, Flatten, Conv2D, MaxPooling2D \n",
        "from keras.layers.normalization import BatchNormalization \n",
        "from keras.optimizers import SGD\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "\n",
        "from numpy import expand_dims\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from matplotlib import pyplot"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4EJpjIYxTsj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4948332a-fa07-4d77-870e-0c99dcfd187c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EI3pK48OK9b4",
        "outputId": "4a8962a6-fa9d-421e-daae-cd6eb3d7e7d1"
      },
      "source": [
        "file_path= '/content/drive/MyDrive/Kaggle-Applied Deep Learning Project/Inputs'\n",
        "folders = os.listdir(file_path)\n",
        "print(folders)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['test.csv', 'train.csv', 'train', 'test']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "MB-J5N4Y1nnC",
        "outputId": "98fe6f63-31ce-46a7-e727-615fe8b20bee"
      },
      "source": [
        "df_train= pd.read_csv('/content/drive/MyDrive/Kaggle-Applied Deep Learning Project/Inputs/train.csv')\n",
        "df_train.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>breed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a8b3ad1dde</td>\n",
              "      <td>nerodia-erythrogaster</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8b492b973d</td>\n",
              "      <td>pantherophis-vulpinus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>929b99ea92</td>\n",
              "      <td>thamnophis-sirtalis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bbac7385e2</td>\n",
              "      <td>pantherophis-obsoletus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ef776b1488</td>\n",
              "      <td>agkistrodon-contortrix</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     image_id                   breed\n",
              "0  a8b3ad1dde   nerodia-erythrogaster\n",
              "1  8b492b973d   pantherophis-vulpinus\n",
              "2  929b99ea92     thamnophis-sirtalis\n",
              "3  bbac7385e2  pantherophis-obsoletus\n",
              "4  ef776b1488  agkistrodon-contortrix"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "PJd-FQqh1yBp",
        "outputId": "458d19aa-b05e-4d0c-f306-af452e2c949e"
      },
      "source": [
        "df_train[\"image_id\"]=\"/content/drive/MyDrive/Kaggle-Applied Deep Learning Project/Inputs/train/\" + df_train[\"image_id\"] + \".jpg\"\n",
        "df_train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>breed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/Kaggle-Applied Deep Lea...</td>\n",
              "      <td>nerodia-erythrogaster</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/Kaggle-Applied Deep Lea...</td>\n",
              "      <td>pantherophis-vulpinus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/Kaggle-Applied Deep Lea...</td>\n",
              "      <td>thamnophis-sirtalis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/Kaggle-Applied Deep Lea...</td>\n",
              "      <td>pantherophis-obsoletus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/Kaggle-Applied Deep Lea...</td>\n",
              "      <td>agkistrodon-contortrix</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            image_id                   breed\n",
              "0  /content/drive/MyDrive/Kaggle-Applied Deep Lea...   nerodia-erythrogaster\n",
              "1  /content/drive/MyDrive/Kaggle-Applied Deep Lea...   pantherophis-vulpinus\n",
              "2  /content/drive/MyDrive/Kaggle-Applied Deep Lea...     thamnophis-sirtalis\n",
              "3  /content/drive/MyDrive/Kaggle-Applied Deep Lea...  pantherophis-obsoletus\n",
              "4  /content/drive/MyDrive/Kaggle-Applied Deep Lea...  agkistrodon-contortrix"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgyZB9ONzcjL"
      },
      "source": [
        "vgg19 = VGG19(include_top=False,\n",
        "              weights='imagenet',\n",
        "              input_shape=(224,224,3),\n",
        "              pooling=None)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmC5lWXa2G0L"
      },
      "source": [
        "for layer in vgg19.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rcKHjIU2Lfo"
      },
      "source": [
        "# Instantiate the sequential model and add the VGG19 model: \n",
        "model = Sequential()\n",
        "model.add(vgg19)\n",
        "\n",
        "# Add the custom layers atop the VGG19 model: \n",
        "model.add(Flatten(name='flattened'))\n",
        "model.add(Dropout(0.3, name='dropout'))\n",
        "model.add(Dense(35, activation='softmax', name='predictions'))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMKXqrQL2RvQ"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDU3SMbJ2bjx"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1/255,\n",
        "        validation_split=0.2,\n",
        "        data_format='channels_last',\n",
        "        rotation_range=30,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='reflect') \n",
        "test_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    data_format='channels_last')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hyRbuke3JFj",
        "outputId": "777d3e09-8b2d-4153-9407-bf64b11e19e8"
      },
      "source": [
        "train_gen = train_datagen.flow_from_dataframe(\n",
        "        dataframe=df_train,\n",
        "        directory=\"/content/drive/MyDrive/Kaggle-Applied Deep Learning Project/Inputs/train/\",\n",
        "        x_col=\"image_id\",\n",
        "        y_col=\"breed\",\n",
        "        subset=\"training\",\n",
        "        batch_size=32,\n",
        "        seed=123,\n",
        "        shuffle=True,\n",
        "        color_mode=\"rgb\",\n",
        "        class_mode=\"categorical\", # this does the work of encoding\n",
        "        target_size=(224,224)) # Change acc to model requirements"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4407 validated image filenames belonging to 35 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-yDwdhc3NfC",
        "outputId": "bd00121b-41a4-432b-9d0a-1917267b0477"
      },
      "source": [
        "test_gen = train_datagen.flow_from_dataframe(\n",
        "        dataframe=df_train,\n",
        "        directory=\"/content/drive/MyDrive/Kaggle-Applied Deep Learning Project/Inputs/train/\",\n",
        "        x_col=\"image_id\",\n",
        "        y_col=\"breed\",\n",
        "        subset=\"validation\",\n",
        "        batch_size=32,\n",
        "        seed=123,\n",
        "        shuffle=True,\n",
        "        color_mode=\"rgb\",\n",
        "        class_mode=\"categorical\", # this does the work of encoding\n",
        "        target_size=(224,224))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1101 validated image filenames belonging to 35 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApHrAXo_Gjix",
        "outputId": "851a2a69-59cf-43a9-b012-67aa3eafff35"
      },
      "source": [
        "model.fit(train_gen, steps_per_epoch=13, \n",
        "                    epochs=65, validation_data=test_gen, \n",
        "                    validation_steps=13)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/65\n",
            "13/13 [==============================] - 35s 1s/step - loss: 5.2878 - accuracy: 0.0523 - val_loss: 4.7406 - val_accuracy: 0.0457\n",
            "Epoch 2/65\n",
            "13/13 [==============================] - 12s 931ms/step - loss: 4.7128 - accuracy: 0.0773 - val_loss: 4.2631 - val_accuracy: 0.0697\n",
            "Epoch 3/65\n",
            "13/13 [==============================] - 11s 915ms/step - loss: 4.2158 - accuracy: 0.0969 - val_loss: 3.8889 - val_accuracy: 0.0913\n",
            "Epoch 4/65\n",
            "13/13 [==============================] - 16s 1s/step - loss: 3.7600 - accuracy: 0.0982 - val_loss: 3.8886 - val_accuracy: 0.0865\n",
            "Epoch 5/65\n",
            "13/13 [==============================] - 11s 878ms/step - loss: 3.6867 - accuracy: 0.1206 - val_loss: 3.9271 - val_accuracy: 0.1034\n",
            "Epoch 6/65\n",
            "13/13 [==============================] - 11s 867ms/step - loss: 3.8974 - accuracy: 0.1307 - val_loss: 3.8178 - val_accuracy: 0.1130\n",
            "Epoch 7/65\n",
            "13/13 [==============================] - 11s 871ms/step - loss: 3.8206 - accuracy: 0.1476 - val_loss: 3.7963 - val_accuracy: 0.1106\n",
            "Epoch 8/65\n",
            "13/13 [==============================] - 11s 861ms/step - loss: 3.6708 - accuracy: 0.2142 - val_loss: 3.9634 - val_accuracy: 0.1202\n",
            "Epoch 9/65\n",
            "13/13 [==============================] - 12s 935ms/step - loss: 3.8183 - accuracy: 0.1465 - val_loss: 3.9404 - val_accuracy: 0.0986\n",
            "Epoch 10/65\n",
            "13/13 [==============================] - 11s 878ms/step - loss: 3.4761 - accuracy: 0.2122 - val_loss: 4.1451 - val_accuracy: 0.0817\n",
            "Epoch 11/65\n",
            "13/13 [==============================] - 11s 868ms/step - loss: 3.5518 - accuracy: 0.1740 - val_loss: 3.6905 - val_accuracy: 0.1202\n",
            "Epoch 12/65\n",
            "13/13 [==============================] - 11s 912ms/step - loss: 3.7176 - accuracy: 0.2211 - val_loss: 3.9884 - val_accuracy: 0.1034\n",
            "Epoch 13/65\n",
            "13/13 [==============================] - 12s 936ms/step - loss: 3.5311 - accuracy: 0.1945 - val_loss: 3.9983 - val_accuracy: 0.1178\n",
            "Epoch 14/65\n",
            "13/13 [==============================] - 11s 887ms/step - loss: 3.3678 - accuracy: 0.2135 - val_loss: 3.8725 - val_accuracy: 0.1250\n",
            "Epoch 15/65\n",
            "13/13 [==============================] - 11s 875ms/step - loss: 3.3319 - accuracy: 0.2050 - val_loss: 3.7585 - val_accuracy: 0.1130\n",
            "Epoch 16/65\n",
            "13/13 [==============================] - 11s 898ms/step - loss: 3.1686 - accuracy: 0.2219 - val_loss: 3.9573 - val_accuracy: 0.1010\n",
            "Epoch 17/65\n",
            "13/13 [==============================] - 12s 937ms/step - loss: 2.9280 - accuracy: 0.2677 - val_loss: 4.0416 - val_accuracy: 0.1106\n",
            "Epoch 18/65\n",
            "13/13 [==============================] - 12s 923ms/step - loss: 3.4416 - accuracy: 0.1912 - val_loss: 4.2399 - val_accuracy: 0.1130\n",
            "Epoch 19/65\n",
            "13/13 [==============================] - 11s 872ms/step - loss: 3.4211 - accuracy: 0.1586 - val_loss: 3.8866 - val_accuracy: 0.1394\n",
            "Epoch 20/65\n",
            "13/13 [==============================] - 11s 871ms/step - loss: 3.2292 - accuracy: 0.2184 - val_loss: 3.7345 - val_accuracy: 0.1490\n",
            "Epoch 21/65\n",
            "13/13 [==============================] - 12s 935ms/step - loss: 3.0048 - accuracy: 0.2604 - val_loss: 3.9439 - val_accuracy: 0.1322\n",
            "Epoch 22/65\n",
            "13/13 [==============================] - 12s 931ms/step - loss: 3.1816 - accuracy: 0.2337 - val_loss: 3.8556 - val_accuracy: 0.1442\n",
            "Epoch 23/65\n",
            "13/13 [==============================] - 11s 875ms/step - loss: 3.0320 - accuracy: 0.2740 - val_loss: 4.1464 - val_accuracy: 0.1082\n",
            "Epoch 24/65\n",
            "13/13 [==============================] - 11s 879ms/step - loss: 3.1649 - accuracy: 0.2384 - val_loss: 3.9131 - val_accuracy: 0.1538\n",
            "Epoch 25/65\n",
            "13/13 [==============================] - 11s 886ms/step - loss: 3.0467 - accuracy: 0.2597 - val_loss: 3.8028 - val_accuracy: 0.1755\n",
            "Epoch 26/65\n",
            "13/13 [==============================] - 12s 936ms/step - loss: 2.8215 - accuracy: 0.2787 - val_loss: 4.1967 - val_accuracy: 0.1226\n",
            "Epoch 27/65\n",
            "13/13 [==============================] - 12s 939ms/step - loss: 3.0150 - accuracy: 0.2466 - val_loss: 3.9205 - val_accuracy: 0.1346\n",
            "Epoch 28/65\n",
            "13/13 [==============================] - 11s 899ms/step - loss: 2.9454 - accuracy: 0.2904 - val_loss: 3.9869 - val_accuracy: 0.1538\n",
            "Epoch 29/65\n",
            "13/13 [==============================] - 11s 869ms/step - loss: 2.9302 - accuracy: 0.2691 - val_loss: 3.5712 - val_accuracy: 0.1659\n",
            "Epoch 30/65\n",
            "13/13 [==============================] - 11s 862ms/step - loss: 2.5478 - accuracy: 0.3340 - val_loss: 3.8440 - val_accuracy: 0.1346\n",
            "Epoch 31/65\n",
            "13/13 [==============================] - 11s 906ms/step - loss: 2.9498 - accuracy: 0.2652 - val_loss: 3.7706 - val_accuracy: 0.1250\n",
            "Epoch 32/65\n",
            "13/13 [==============================] - 12s 918ms/step - loss: 2.8537 - accuracy: 0.2905 - val_loss: 4.1260 - val_accuracy: 0.1418\n",
            "Epoch 33/65\n",
            "13/13 [==============================] - 11s 872ms/step - loss: 2.6079 - accuracy: 0.2935 - val_loss: 4.0830 - val_accuracy: 0.1346\n",
            "Epoch 34/65\n",
            "13/13 [==============================] - 11s 876ms/step - loss: 2.8262 - accuracy: 0.2917 - val_loss: 4.2153 - val_accuracy: 0.1130\n",
            "Epoch 35/65\n",
            "13/13 [==============================] - 11s 887ms/step - loss: 2.8529 - accuracy: 0.3344 - val_loss: 3.9230 - val_accuracy: 0.1514\n",
            "Epoch 36/65\n",
            "13/13 [==============================] - 12s 927ms/step - loss: 3.0093 - accuracy: 0.2753 - val_loss: 3.8010 - val_accuracy: 0.1755\n",
            "Epoch 37/65\n",
            "13/13 [==============================] - 11s 870ms/step - loss: 2.7961 - accuracy: 0.3217 - val_loss: 3.9377 - val_accuracy: 0.1490\n",
            "Epoch 38/65\n",
            "13/13 [==============================] - 11s 872ms/step - loss: 2.9041 - accuracy: 0.2804 - val_loss: 3.9852 - val_accuracy: 0.1250\n",
            "Epoch 39/65\n",
            "13/13 [==============================] - 11s 864ms/step - loss: 2.8279 - accuracy: 0.3433 - val_loss: 4.3866 - val_accuracy: 0.1418\n",
            "Epoch 40/65\n",
            "13/13 [==============================] - 11s 879ms/step - loss: 2.7657 - accuracy: 0.3230 - val_loss: 4.4245 - val_accuracy: 0.0865\n",
            "Epoch 41/65\n",
            "13/13 [==============================] - 12s 930ms/step - loss: 2.6737 - accuracy: 0.3015 - val_loss: 3.9807 - val_accuracy: 0.1635\n",
            "Epoch 42/65\n",
            "13/13 [==============================] - 12s 932ms/step - loss: 2.5379 - accuracy: 0.3352 - val_loss: 3.9805 - val_accuracy: 0.1466\n",
            "Epoch 43/65\n",
            "13/13 [==============================] - 11s 859ms/step - loss: 2.6639 - accuracy: 0.3213 - val_loss: 4.1006 - val_accuracy: 0.1346\n",
            "Epoch 44/65\n",
            "13/13 [==============================] - 11s 859ms/step - loss: 2.5547 - accuracy: 0.3414 - val_loss: 4.1537 - val_accuracy: 0.1106\n",
            "Epoch 45/65\n",
            "13/13 [==============================] - 12s 936ms/step - loss: 2.5578 - accuracy: 0.3401 - val_loss: 3.7608 - val_accuracy: 0.1538\n",
            "Epoch 46/65\n",
            "13/13 [==============================] - 12s 935ms/step - loss: 2.7210 - accuracy: 0.3862 - val_loss: 4.2949 - val_accuracy: 0.1298\n",
            "Epoch 47/65\n",
            "13/13 [==============================] - 12s 927ms/step - loss: 2.7439 - accuracy: 0.3245 - val_loss: 4.5300 - val_accuracy: 0.1226\n",
            "Epoch 48/65\n",
            "13/13 [==============================] - 12s 930ms/step - loss: 2.6499 - accuracy: 0.3246 - val_loss: 4.7249 - val_accuracy: 0.1250\n",
            "Epoch 49/65\n",
            "13/13 [==============================] - 11s 870ms/step - loss: 2.8300 - accuracy: 0.3174 - val_loss: 4.2572 - val_accuracy: 0.1274\n",
            "Epoch 50/65\n",
            "13/13 [==============================] - 11s 852ms/step - loss: 2.6972 - accuracy: 0.3022 - val_loss: 4.5568 - val_accuracy: 0.0889\n",
            "Epoch 51/65\n",
            "13/13 [==============================] - 11s 859ms/step - loss: 2.5233 - accuracy: 0.3664 - val_loss: 4.2611 - val_accuracy: 0.1442\n",
            "Epoch 52/65\n",
            "13/13 [==============================] - 12s 928ms/step - loss: 2.4560 - accuracy: 0.3462 - val_loss: 4.1067 - val_accuracy: 0.1466\n",
            "Epoch 53/65\n",
            "13/13 [==============================] - 11s 864ms/step - loss: 2.6884 - accuracy: 0.3359 - val_loss: 3.9741 - val_accuracy: 0.1346\n",
            "Epoch 54/65\n",
            "13/13 [==============================] - 11s 858ms/step - loss: 2.6783 - accuracy: 0.3466 - val_loss: 4.1919 - val_accuracy: 0.1466\n",
            "Epoch 55/65\n",
            "13/13 [==============================] - 12s 933ms/step - loss: 2.4782 - accuracy: 0.3685 - val_loss: 3.9399 - val_accuracy: 0.1635\n",
            "Epoch 56/65\n",
            "13/13 [==============================] - 12s 926ms/step - loss: 2.4330 - accuracy: 0.3639 - val_loss: 3.8512 - val_accuracy: 0.1731\n",
            "Epoch 57/65\n",
            "13/13 [==============================] - 11s 862ms/step - loss: 2.5100 - accuracy: 0.3572 - val_loss: 4.1735 - val_accuracy: 0.1611\n",
            "Epoch 58/65\n",
            "13/13 [==============================] - 11s 860ms/step - loss: 2.4702 - accuracy: 0.3519 - val_loss: 4.1723 - val_accuracy: 0.1562\n",
            "Epoch 59/65\n",
            "13/13 [==============================] - 12s 913ms/step - loss: 2.4838 - accuracy: 0.3833 - val_loss: 4.0366 - val_accuracy: 0.1466\n",
            "Epoch 60/65\n",
            "13/13 [==============================] - 12s 928ms/step - loss: 2.4256 - accuracy: 0.3594 - val_loss: 4.0821 - val_accuracy: 0.1466\n",
            "Epoch 61/65\n",
            "13/13 [==============================] - 11s 874ms/step - loss: 2.1937 - accuracy: 0.4110 - val_loss: 4.1186 - val_accuracy: 0.1442\n",
            "Epoch 62/65\n",
            "13/13 [==============================] - 11s 864ms/step - loss: 2.3823 - accuracy: 0.4029 - val_loss: 3.9904 - val_accuracy: 0.1274\n",
            "Epoch 63/65\n",
            "13/13 [==============================] - 12s 928ms/step - loss: 2.3705 - accuracy: 0.3776 - val_loss: 4.2954 - val_accuracy: 0.1082\n",
            "Epoch 64/65\n",
            "13/13 [==============================] - 11s 858ms/step - loss: 2.4439 - accuracy: 0.3821 - val_loss: 4.0336 - val_accuracy: 0.1490\n",
            "Epoch 65/65\n",
            "13/13 [==============================] - 11s 866ms/step - loss: 2.6326 - accuracy: 0.3657 - val_loss: 3.9933 - val_accuracy: 0.1562\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f52e808d410>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfA1SAty3UE2"
      },
      "source": [
        "#model.fit(train_gen, steps_per_epoch=15, \n",
        "                    #epochs=16, validation_data=test_gen, \n",
        "                    #validation_steps=15)"
      ],
      "execution_count": 14,
      "outputs": []
    }
  ]
}